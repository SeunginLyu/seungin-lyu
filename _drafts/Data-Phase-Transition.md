---
title: Tell the Story of Your Data
layout: post
date: 2018-09-26 02:09:19 +0000
comments: false

---
* Representations of various phenomena
* Contextual collections of things
* Translation of the world into human-defined objects

Today, we are surrounded by an unprecedented mass of data, yet people still have distinctively varying views on what "data" exactly means. This above list is my attempt to come up with a reasonable description of what data is, but I'm sure there are million other ways to explain it differently. 

By going through _Representation and the Necessity of Interpretation_ by Laura Kurgan and _Objectivity_ by Lorraine Daston, Peter Galison, I developed a mental model of data that somewhat weaves together the complexities of data such as objective truth, subjective interpretations and etc.

I see data as **frozen snippets of encrypted human stories**. 

They are **encrypted** because often times there are hidden secrets that are impossible to be discovered unless we are "provided" the keys to unveil them. The encrypted secretes include :

* Who/what collected the data?
* Who chose to produce the data?
* When and where was the data captured?

While the general public indulges in the wide availability of open data nowadays (i.e Google Earth photos, Wikipedia, etc.), we should still remark that these datasets seldom come packaged with the secrets and stories of their origins. It feels like all datasets should claim unique stories behind them because real "people" have taken efforts and actions to create them. Nonetheless, unless we go actively hunt for the keys to these datasets (that might not even exist), we are still left with partially encrypted datasets that are subject to subjective inferences based on the relatively small portion of the story that has been decrypted for us. 

Thus, it is no surprise that people propose a wide spectrum of interpretations given the same datasets. Provided limited knowledge, the directions of these interpretations are inevitably biased with individual prior knowledge, and we should acknowledge that the "trustworthiness" of such inferences are applicable only within the systems that provided the rules and standards to form such inferences. For example, a Bayesian thinker would argue that the p-values calculated from a frequentist point view are not trustworthy, but the frequentists would argue the other way around. 

Moreover, I call data **frozen snippets** because we only see the frozen phase of data which in fact goes through phase transitions.

1.  Objectify Phase
2. 
3.  